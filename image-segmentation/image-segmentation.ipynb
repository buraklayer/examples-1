{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z581vcF8XL9s",
        "outputId": "f7ede2c3-7135-45f5-db86-674027831048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 793 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 428 kB 49.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 43.1 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.13.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 471 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 61.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 16.8 MB 63.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 256 kB 34.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 30.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 62.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 54.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 60.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 26.7 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 159 kB 65.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 39.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 47.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 53.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 739 kB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 41.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 56.0 MB/s \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/b8/ab/c7abc950e222c4cab5f7fd92107f3b09553061f673f1a670e6569105f584/grpcio-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=cc135b77f384a84bac67a37947886986be136356446338d64160a30c85f20c6d (from https://pypi.org/simple/grpcio/) (requires-python:>=3.6))\n",
            "Reason for being yanked: Segfaults\u001b[0m\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio-tools' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/be/e1/70dac693e6df7e4f3108dfd3a82f86f0cd3742d9afe98bb2fe4333a3edd7/grpcio_tools-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7db11a65e07410db1c31cbeb9afe344a6bd88a63dcd819557707ca7318478727 (from https://pypi.org/simple/grpcio-tools/) (requires-python:>=3.6))\n",
            "Reason for being yanked: grpcio 1.45.0 was yanked\u001b[0m\n",
            "\u001b[?25h  Building wheel for validate-email (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for polling (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython ipykernel --upgrade -q\n",
        "!pip install layer-sdk --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4jm219G_t3l"
      },
      "outputs": [],
      "source": [
        "pip install git+https://github.com/tensorflow/examples.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klVZE2Ks_nvZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R3dUIhxA0Gb"
      },
      "outputs": [],
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask\n",
        "\n",
        "def load_image(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask\n",
        "\n",
        "class Augment(tf.keras.layers.Layer):\n",
        "  def __init__(self, seed=42):\n",
        "    super().__init__()\n",
        "    # both use the same seed, so they'll make the same random changes.\n",
        "    self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
        "    self.augment_labels = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
        "\n",
        "  def call(self, inputs, labels):\n",
        "    inputs = self.augment_inputs(inputs)\n",
        "    labels = self.augment_labels(labels)\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwBKrXn6XkMC"
      },
      "outputs": [],
      "source": [
        "import layer\n",
        "from layer.decorators import model\n",
        "\n",
        "layer.login()\n",
        "layer.init('image-segmentation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE0HGD_CWqSb"
      },
      "outputs": [],
      "source": [
        "@model('base-model')\n",
        "def build_base_model():\n",
        "  return tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
        "\n",
        "build_base_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUj_T0uQXxo7"
      },
      "outputs": [],
      "source": [
        "# Create the feature extraction model\n",
        "@model('down-stack-model')\n",
        "def build_down_stack_model():\n",
        "  base_model = layer.get_model('base-model').get_train()\n",
        "\n",
        "  # Use the activations of these layers\n",
        "  layer_names = [\n",
        "      'block_1_expand_relu',   # 64x64\n",
        "      'block_3_expand_relu',   # 32x32\n",
        "      'block_6_expand_relu',   # 16x16\n",
        "      'block_13_expand_relu',  # 8x8\n",
        "      'block_16_project',      # 4x4\n",
        "  ]\n",
        "  base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
        "  down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
        "  down_stack.trainable = False\n",
        "  return down_stack\n",
        "\n",
        "build_down_stack_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF4uBMNAFKHb"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "def make_display_figure(display_list):\n",
        "  figure = plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    ax = figure.add_subplot(1, len(display_list), i+1)\n",
        "    ax.set_title(title[i])\n",
        "    ax.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "    ax.set_axis_off()\n",
        "  return figure\n",
        "\n",
        "def make_display_image(display_list):\n",
        "    fig = make_display_figure(display_list)\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf)\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf)\n",
        "    plt.close()\n",
        "    return img\n",
        "\n",
        "def display(display_list):\n",
        "  make_display_figure(display_list).show()\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]\n",
        "\n",
        "def get_figures(dataset, num=1, model_train=None):\n",
        "  figures = []\n",
        "  for image, mask in dataset.take(num):\n",
        "    display_list = [image[0], mask[0]]\n",
        "    if model_train:\n",
        "      pred_mask = model_train.predict(image)\n",
        "      display_list.append(create_mask(pred_mask))\n",
        "    figures.append(make_display_image(display_list))\n",
        "  return figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FKo1qB9FD7S"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "import io\n",
        "\n",
        "\n",
        "\n",
        "class LayerCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    layer.log(logs, step=epoch)\n",
        "\n",
        "\n",
        "@model('model')\n",
        "def build_model():\n",
        "  dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
        "\n",
        "  OUTPUT_CLASSES = 3\n",
        "  TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "  BATCH_SIZE = 64\n",
        "  BUFFER_SIZE = 1000\n",
        "  STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "  EPOCHS = 30\n",
        "  VAL_SUBSPLITS = 5\n",
        "  VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "  layer.log({\n",
        "    'TRAIN_LENGTH': TRAIN_LENGTH,\n",
        "    'BATCH_SIZE': BATCH_SIZE,\n",
        "    'BUFFER_SIZE': BUFFER_SIZE,\n",
        "    'OUTPUT_CLASSES': OUTPUT_CLASSES,\n",
        "    'EPOCHS': EPOCHS,\n",
        "    'STEPS_PER_EPOCH': STEPS_PER_EPOCH,\n",
        "    'VAL_SUBSPLITS': VAL_SUBSPLITS,\n",
        "    'VALIDATION_STEPS': VALIDATION_STEPS,\n",
        "  })\n",
        "\n",
        "  train_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  test_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "  train_batches = (\n",
        "      train_images\n",
        "      .cache()\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .repeat()\n",
        "      .map(Augment())\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
        "\n",
        "  test_batches = test_images.batch(BATCH_SIZE)\n",
        "\n",
        "  for ix, fig in enumerate(get_figures(train_batches, num=4)):\n",
        "    layer.log({f'sample_{ix}': fig})\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "\n",
        "  # Downsampling through the model\n",
        "  down_stack = layer.get_model('down-stack-model').get_train()\n",
        "  skips = down_stack(inputs)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  up_stack = [\n",
        "      pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "      pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "      pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "      pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "  ]\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      filters=OUTPUT_CLASSES, kernel_size=3, strides=2,\n",
        "      padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  segmentation_model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "  segmentation_model.compile(\n",
        "      optimizer='adam',\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "  #shape_plot = tf.keras.utils.plot_model(segmentation_model, show_shapes=True)\n",
        "  #layer.log({\n",
        "  #    'shape_plot': PIL.Image.open(io.BytesIO(shape_plot.data)) ,\n",
        "  #})\n",
        "  for ix, fig in enumerate(get_figures(train_batches, num=4, model_train=segmentation_model)):\n",
        "    layer.log({f'prediction_initial_{ix}': fig})\n",
        "\n",
        "  model_history = segmentation_model.fit(\n",
        "      train_batches,\n",
        "      epochs=EPOCHS,\n",
        "      steps_per_epoch=STEPS_PER_EPOCH,\n",
        "      validation_steps=VALIDATION_STEPS,\n",
        "      validation_data=test_batches,\n",
        "      callbacks=[LayerCallback()])\n",
        "  \n",
        "  for ix, fig in enumerate(get_figures(train_batches, num=4, model_train=segmentation_model)):\n",
        "    layer.log({f'prediction_final_{ix}': fig})\n",
        "\n",
        "  return segmentation_model\n",
        "\n",
        "build_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Volkan - Image Segmentation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}